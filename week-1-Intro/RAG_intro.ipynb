{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00f9feb-d049-4321-a980-3d8c0b04bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-21 18:19:29--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-06-21 18:19:29 (14.5 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e617c6bf-f0e4-4056-b167-2c079f33064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91284b9-863f-4ef2-8e07-7c78b9879543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5bbfb9f-5ac4-41ef-ba6e-ca8b2782bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc696bb7-ac65-49bf-a17c-9a2649151f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde0313d-6e4a-4d23-bf10-d2e0c98a2b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6fff5d3-0aa1-465c-8fcf-317cabb76c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da44e006-f6f8-447e-a094-5c9789fe3dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'the course has already started, can I still enroll?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecc9cad1-70a4-4e8c-a343-19590b449d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7a3123d8b370>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "044d2151-7077-4511-92a4-064f3a59527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7322bab8-feaf-418a-b4d2-d221b57bce5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\",\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Module “kafka” not found when trying to run producer.py',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\",\n",
       "  'section': 'Workshop 1 - dlthub',\n",
       "  'question': 'How do I install the necessary dependencies to run the code?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Run this command in terminal in the same directory (/docker/spark):\\nchmod +x build.sh',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Python Kafka: ./build.sh: Permission denied Error',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'According to https://github.com/dpkp/kafka-python/\\n“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO USE https://github.com/wbarnha/kafka-python-ng FOR THE TIME BEING”\\nUse pip install kafka-python-ng instead',\n",
       "  'section': 'Project',\n",
       "  'question': 'How to fix the error \"ModuleNotFoundError: No module named \\'kafka.vendor.six.moves\\'\"?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'how do I run kafka?'\n",
    "search_results = search(query)\n",
    "\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a28c8ca-a81f-4d75-88c8-b0572e3611b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "383cfa74-40c9-4747-a508-f597ddbb8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(query, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2b533b4-70b6-4c51-a67b-2bc4ec24c031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You\\'re a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\\n    Use only the facts from the CONTEXT when answering the QUESTION.\\n    \\n    QUESTION: how do I run kafka?\\n    \\n    CONTEXT: \\n    section: Module 6: streaming with kafka\\nquestion: Java Kafka: How to run producer/consumer/kstreams/etc in terminal\\nanswer: In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n\\nsection: Module 6: streaming with kafka\\nquestion: Module “kafka” not found when trying to run producer.py\\nanswer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you\\'ll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it\\'s env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\\n\\nsection: Workshop 1 - dlthub\\nquestion: How do I install the necessary dependencies to run the code?\\nanswer: Answer: To run the provided code, ensure that the \\'dlt[duckdb]\\' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\\n\\nsection: Module 6: streaming with kafka\\nquestion: Python Kafka: ./build.sh: Permission denied Error\\nanswer: Run this command in terminal in the same directory (/docker/spark):\\nchmod +x build.sh\\n\\nsection: Project\\nquestion: How to fix the error \"ModuleNotFoundError: No module named \\'kafka.vendor.six.moves\\'\"?\\nanswer: According to https://github.com/dpkp/kafka-python/\\n“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO USE https://github.com/wbarnha/kafka-python-ng FOR THE TIME BEING”\\nUse pip install kafka-python-ng instead'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d56a6fe9-e5db-45db-b83f-d530521eee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1370219a-f407-4b36-80d5-2bb2f4ae8051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "client = MistralClient(api_key=api_key)\n",
    "\n",
    "\n",
    "def llm_chatbot(prompt):\n",
    "    response = client.chat(\n",
    "        model='open-mistral-7b',\n",
    "        messages=[\n",
    "            ChatMessage(role=\"user\", content=prompt)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57a6192b-6833-468e-a207-ddb418a18f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_chatbot(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c35c8142-e781-4793-a9d6-92cb02b9c7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To run Kafka using Java, follow the steps below:\\n\\n1. Navigate to your project directory.\\n2. Run the following command in the terminal:\\n\\n```\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n```\\n\\nReplace `<jar_name>` with the name of your JAR file.\\n\\nFor running Kafka using Python:\\n\\n1. If you\\'re using a virtual environment, create and activate it using the following commands:\\n\\n```\\npython -m venv env\\nsource env/bin/activate\\n```\\n\\n2. Install the required packages using:\\n\\n```\\npip install -r requirements.txt\\n```\\n\\n3. Activate the virtual environment (run this command every time you need the virtual environment):\\n\\n```\\nsource env/bin/activate\\n```\\n\\n4. Deactivate the virtual environment when you\\'re done:\\n\\n```\\ndeactivate\\n```\\n\\nIf you encounter the error \"Module “kafka” not found when trying to run producer.py,\" try creating a virtual environment and installing the required packages.\\n\\nIf you\\'re using a Docker environment, ensure that the \\'dlt[duckdb]\\' package is installed for the provided code.\\n\\nIf you\\'re encountering a permission denied error while running `./build.sh`, run this command:\\n\\n```\\nchmod +x build.sh\\n```\\n\\nIf you\\'re experiencing the error \"ModuleNotFoundError: No module named \\'kafka.vendor.six.moves\\'\", try using the kafka-python-ng package instead of the regular kafka-python:\\n\\n```\\npip install kafka-python-ng\\n```'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c917048-e2c8-4ae7-b0b7-10f264bcfd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'the course has already started, can I still enroll?'\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm_chatbot(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86899abf-0cb5-4cb6-b1c9-b844d58e1362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, you can still enroll in the course after it has started, but you will be eligible to submit the homeworks. However, you should be aware of the deadlines for turning in the final projects. The exact starting date of the course is the 15th of January 2024 at 17h00. Before the course starts, you can prepare by installing and setting up all the dependencies and requirements such as a Google cloud account, Google Cloud SDK, Python 3, Terraform, and Git. You can also look over the prerequisites and syllabus to see if you are comfortable with these subjects. For support, you can use the Slack channel even if you are in a self-paced mode.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31cacf08-2fa4-497e-85ff-ab35cc89760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b40c8ece-bcd7-4cdf-835d-f92b8d30f33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch(['http://localhost:9200'])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "es_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b446299-21a5-4496-9f89-17142124eba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edf9d2ae-6cdb-43dc-852a-3d463a4811dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9632ecc4-7389-4cdb-b398-bfda2ba95624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 948/948 [00:24<00:00, 38.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b3c8ba3-7d35-45be-947e-2c33af9605c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e5b521b-d9b3-4533-aaf3-48371f748271",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'I just disovered the course. Can I still join it?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11d81cd4-82e4-4209-a8c8-0eb3adc20129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e866f39a-5193-4990-adec-c048e0ed5ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, you can still join the course even though it has already started. You can follow the course materials at your own pace and submit the homeworks. However, be aware of the deadlines for turning in the final projects. Before the course starts, you can install and set up all the dependencies and requirements such as Google cloud account, Google Cloud SDK, Python 3 (installed with Anaconda), Terraform, and Git. You can also join the Slack channel for support if you take the course in the self-paced mode. You don't need a confirmation email after registering for the Data Engineering Bootcamp.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea433cd-0c1b-4a00-b1bc-9aad720e3308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
